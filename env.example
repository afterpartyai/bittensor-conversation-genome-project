export SYSTEM_MODE=production

# ____________ Miners and Validators Deployment Configuration: ________________
export COLDKEY_NAME=default
export HOTKEY_NAME=default
export TYPE=miner

export NETWORK=test
export PORT=60000
export IP=0.0.0.0

# Enables DEBUG logging
export DEBUG_MODE=true

# OpenAI key is always required for Default Settings and Embedding Model usage. Please enter:
export OPENAI_API_KEY=

# ____________ WANDB: ________________
# WandB Key is only required for validators.
# Get a free key from the Weights & Biases website at: https://wandb.ai/site
export WANDB_API_KEY=
export WAND_ENABLED=0

# ____________ OpenAI Configuration: ________________
# OpenAI is the default LLM provider for all miner and validator operations, utilizing GPT-4o.
# To override your OpenAI model choice, uncomment the line below, then proceed to selecting a model. For other override options, see "Select LLM Override" below.
#export LLM_TYPE_OVERRIDE=openai

#Enter a model below. See all options at: https://platform.openai.com/docs/models
#export OPENAI_MODEL=gpt-3.5-turbo
#export OPENAI_MODEL=gpt-4-turbo

# Uncomment to use direct API call instead of OpenAI Package. Commented out by default
# NOTE: if you are updating from an older version, make sure you re-install requirements.txt before running with direct call commented this out
#export OPENAI_DIRECT_CALL=1


# ____________ Embeddings Model ________________
# DO NOT CHANGE. Ensures compatibility between Validators & Miners
export OPENAI_EMBEDDINGS_MODEL=text-embedding-ada-002


# ____________ Select LLM Override________________
# OpenAI is the default LLM provider for all miner and validator operations, utilizing GPT-4o. configure an override LLM choice (Not Recommended)
# Validators: This will determine which API you use to Generate Full Convo Tags and Validate Miner Tags
# Miners: This will determine which API is used to generate your window tags.
# Note that the Llama models can be used through Groq and the Claude models can be used through Anthropic
#export LLM_TYPE_OVERRIDE=groq
#export LLM_TYPE_OVERRIDE=anthropic


# Continue below for additional configuration based on your override selection(s)

# ____________ GROQ Configuration: ________________
# *** Below Fields Required if you chose LLM_TYPE=groq -- https://groq.com/ ***
export GROQ_API_KEY=

# Enter a model below. See all options (use model ID): https://console.groq.com/docs/models
export GROQ_MODEL=llama3-8b-8192

# DO NOT CHANGE - required if LLM_TYPE=groq
export GROQ_DIRECT_CALL=1


# ____________ ANTHROPIC Configuration: ________________
# *** Below Fields Required if you chose LLM_TYPE=anthropic -- https://claude.ai/ ***
export ANTHROPIC_API_KEY=

# Enter a model below. See all options (use "Latest 1P API model name"): https://docs.anthropic.com/en/docs/about-claude/models#model-names
export ANTHROPIC_MODEL=claude-3-sonnet-20240229


# ____________ DB Read/Write Configuration: ____________
# For Validators. Read from api.conversations.xyz
export CGP_API_READ_HOST=https://api.conversations.xyz
export CGP_API_READ_PORT=443

# For Validators. Write to db.conversations.xyz
export CGP_API_WRITE_HOST=https://db.conversations.xyz
export CGP_API_WRITE_PORT=443

# For Validators. Used for local DB Configuration
# If you want to run a local API you can adjust the following variables:
export START_LOCAL_CGP_API=false
export LOCAL_CGP_API_PORT=8000

# You will also need to uncomment lines below
# See "Validating with a Custom Conversation Server" in the Readme.md for further information
#export CGP_API_READ_HOST=http://localhost
#export CGP_API_READ_PORT=$LOCAL_CGP_API_PORT

# Only uncomment this for local testing
#export CGP_API_WRITE_HOST=http://localhost
#export CGP_API_WRITE_PORT=$LOCAL_CGP_API_PORT

# ____________ Debug Log: ____________
# Optional, Commented by default.
# Uncomment to set a path to log the conversation windows and tags you mine for analysis
# export SCORING_DEBUG_LOG=./scoring_debug.log
